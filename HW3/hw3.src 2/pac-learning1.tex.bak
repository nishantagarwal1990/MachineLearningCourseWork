\section{PAC Learning}
\label{sec:pac-learning}
\begin{enumerate}

\item ~[15 points] Due to the recent budget cuts the government no
  longer has any money to pay for humans to monitor the state of
  nuclear reactors. They have charged you with assessing a Robot's
  ability to perform this vital task. Every reactor has a different
  number of binary gauges which indicate whether or not some aspect of
  the reaction is {\tt normal} or {\tt strange}. The reactor itself
  can be in one of {\bf five} states -- {\em Normal}, {\em Meltdown},
  {\em Pre-meltdown}, {\em Abnormally cool} or {\em Off}. Each
  combination of the binary guage settings indicate one of these five
  reactor states. We want to know if we can train a robot to identify
  which gauges and gauge combinations are responsible for each reactor
  state.

  \begin{enumerate}
  \item [a)][5 points] Suppose that we have $N$ gauges with which to
    identify reactor states. How large is the hypothesis space for
    this task? (You may have to make assumptions about the underlying
    function space. State your assumptions clearly.)

  \item[b)] [10 points] The ex-government employee, whose job the
    robot is taking, trains the robot at a nuclear reactor where there
    are 20 gauges by showing the robot a set of gauge positions for
    the five different reactor states. If the robot wants to learn to
    recognize the reactor's condition with .1 percent error with
    greater than 99\% probability how many examples does the robot
    need to see?

  \end{enumerate}


\item ~[5 points] Is it possible for a learned hypothesis $h$ to
   achieve 100\% accuracy with respect to a training set and still
   have non-zero true error? If so, provide a description of how this
   is possible. If not, prove that it is impossible.


\item ~[25 points] {\bf Learning decision lists:}
  \input{decision-lists}

\item ~[20 points, {\bf CS 6350 students only}] Let $X$ be an instance
  space and let $D_1,D_2,...,D_m$ be a sequence of distributions over
  $X$. Let $\mathcal{H}$ be a finite class of binary classifiers over
  $X$ and let $f\in \mathcal{H}$. 

  Suppose we have a sample $S$ of $m$ examples, such that the
  instances are independent but are not identically distributed. The
  $i^{th}$ instance is sampled from $D_i$ and then $y_i$ is set to be
  $f(x_i)$. Let $\bar{D}_m$ denote the average, that is,
  $\bar{D}_m = \frac{1}{m}\sum_{i=1}^m D_i$. 

  Let $h \in \mathcal{H}$ be a classifier that gets zero error on the
  training set. That is, for every example $x_i \in X$, we have
  $h(x_i) = f(x_i)$. Show that, for any accuracy parameter
  $\epsilon \in (0, 1)$, the probability that the expected error of
  the learned classifier $h$ is greater than $\epsilon$ is no more
  than $|\mathcal{H}|e^{-\epsilon m}$. That is, show that

  \[\mathbb{P}\left[E_{x \sim \bar{D}_m}\left[h(x) \ne f(x)\right]> \epsilon\right] \leq  |\mathcal{H}|e^{-\epsilon m}\]

  (Hint: You have to use the fact that the arithmetic mean of a set of
  non-negative numbers greater than or equal to their geometric mean.)

\end{enumerate}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "hw3"
%%% End:
